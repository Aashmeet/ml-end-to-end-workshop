{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING END TO END \n",
    " \n",
    "You deploy Inference Pipelines in Amazon SageMaker to execute a sequence of pre-processing, inference, and post-processing steps on real-time and batch inference requests. This makes it easy to build and deploy feature preprocessing pipelines with a suite of feature transformers available in the new SparkML and scikit-learn containers in Amazon SageMaker. You can write your data processing code once and reuse it for training and inference which provides consistency in your machine learning workflows and easier management of your models. You can deploy upto five steps in your inference pipeline and they all execute on the same instance so there is minimal latency impact. The same inference pipeline can be used for real-time and batch inferences.\n",
    "\n",
    "# Part 1 - Data Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodologies\n",
    "The Notebook consists of a few high-level steps:\n",
    "\n",
    "* Using AWS Glue for executing the SparkML feature pre-processing and postprocessing job.\n",
    "* Using SageMaker XGBoost to train on the processed dataset produced by SparkML job.\n",
    "* Building an Inference Pipeline consisting of SparkML & XGBoost models for a realtime inference endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using AWS Glue for executing the SparkML job\n",
    "\n",
    "We'll be running the SparkML job using [AWS Glue](https://aws.amazon.com/glue). AWS Glue is a serverless ETL service which can be used to execute standard Spark/PySpark jobs. Glue currently only supports `Python 2.7`, hence we'll write the script in `Python 2.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmazonSageMaker-ExecutionRole-20190429T035455\n"
     ]
    }
   ],
   "source": [
    "# Import SageMaker Python SDK to get the Session and execution_role\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(role[role.rfind('/') + 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Adding AWS Glue as an additional trusted entity to this role\n",
    "This step is needed if you want to pass the execution role of this Notebook while calling Glue APIs as well without creating an additional **Role**. If you have not used AWS Glue before, then this step is mandatory.\n",
    "\n",
    "If you have used AWS Glue previously, then you should have an already existing role that can be used to invoke Glue APIs. In that case, you can pass that role while calling Glue (later in this notebook) and skip this next step.\n",
    "\n",
    "On the IAM dashboard, please click on **Roles** on the left sidenav and search for this Role. Once the Role appears, click on the **Role** to go to its Summary page. Click on the **Trust relationships** tab on the **Summary** page to add AWS Glue as an additional trusted entity.\n",
    "\n",
    "Click on **Edit trust relationship** and replace the JSON with this JSON.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": [\n",
    "          \"sagemaker.amazonaws.com\",\n",
    "          \"glue.amazonaws.com\"\n",
    "        ]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Once this is complete, click on **Update Trust Policy** and you are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Setup S3 bucket\n",
    "\n",
    "First, we need to setup an S3 bucket within your account, and upload the necessary files to this bucket. To setup the bucket, we will run the first code block, labeled Setup S3 bucket. To run the cell while the code cell is selected, you can either press Shift and Return at the same time or select the Run button at the top of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save this S3 bucket name for the rest of this process: sagemaker-glue-process-277454758150-us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from sagemaker import Session as Sess\n",
    "\n",
    "# SageMaker session\n",
    "sess = Sess()\n",
    "\n",
    "# Boto3 session\n",
    "session = boto3.session.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "account = session.client('sts').get_caller_identity()['Account']\n",
    "region = session.region_name\n",
    "bucket_name = 'sagemaker-glue-process-{}-{}'.format(account,region)\n",
    "\n",
    "try:\n",
    "    if region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    message = e.response['Error']['Message']\n",
    "    if error_code == 'BucketAlreadyOwnedByYou':\n",
    "        print ('A bucket with the same name already exists in your account - using the same bucket.')\n",
    "        pass\n",
    "\n",
    "print(\"\\nSave this S3 bucket name for the rest of this process: {}\".format(bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make note of the S3 bucket name that was created here. If you are planning to follow along in the console, you will need this name for later.\n",
    "\n",
    "## 1.3 Upload files to S3\n",
    "\n",
    "Now we need to upload the raw data and Glue processing script to S3. We can do that by running the code blocks in the notebook labeled Upload files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-04-30 23:54:16--  https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51867 (51K) [application/x-httpd-php]\n",
      "Saving to: ‘car.data.3’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 98%  351K 0s\n",
      "    50K                                                       100% 1242G=0.1s\n",
      "\n",
      "2019-04-30 23:54:16 (355 KB/s) - ‘car.data.3’ saved [51867/51867]\n",
      "\n",
      "--2019-04-30 23:54:16--  https://s3-us-west-2.amazonaws.com/sparkml-mleap/0.9.6/python/python.zip\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.248.152\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.248.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36872 (36K) [application/zip]\n",
      "Saving to: ‘python.zip.3’\n",
      "\n",
      "     0K .......... .......... .......... ......               100%  475K=0.08s\n",
      "\n",
      "2019-04-30 23:54:17 (475 KB/s) - ‘python.zip.3’ saved [36872/36872]\n",
      "\n",
      "--2019-04-30 23:54:17--  https://s3-us-west-2.amazonaws.com/sparkml-mleap/0.9.6/jar/mleap_spark_assembly.jar\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.224.184\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.224.184|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17319576 (17M) [application/java-archive]\n",
      "Saving to: ‘mleap_spark_assembly.jar.3’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  314K 54s\n",
      "    50K .......... .......... .......... .......... ..........  0% 52.7M 27s\n",
      "   100K .......... .......... .......... .......... ..........  0%  630K 27s\n",
      "   150K .......... .......... .......... .......... ..........  1% 78.2M 20s\n",
      "   200K .......... .......... .......... .......... ..........  1%  632K 21s\n",
      "   250K .......... .......... .......... .......... ..........  1% 61.3M 18s\n",
      "   300K .......... .......... .......... .......... ..........  2% 79.7M 15s\n",
      "   350K .......... .......... .......... .......... ..........  2%  107M 13s\n",
      "   400K .......... .......... .......... .......... ..........  2% 97.4M 12s\n",
      "   450K .......... .......... .......... .......... ..........  2%  645K 13s\n",
      "   500K .......... .......... .......... .......... ..........  3% 95.0M 12s\n",
      "   550K .......... .......... .......... .......... ..........  3%  149M 11s\n",
      "   600K .......... .......... .......... .......... ..........  3%  129M 10s\n",
      "   650K .......... .......... .......... .......... ..........  4% 95.3M 9s\n",
      "   700K .......... .......... .......... .......... ..........  4%  183M 9s\n",
      "   750K .......... .......... .......... .......... ..........  4% 91.9M 8s\n",
      "   800K .......... .......... .......... .......... ..........  5%  122M 8s\n",
      "   850K .......... .......... .......... .......... ..........  5%  153M 7s\n",
      "   900K .......... .......... .......... .......... ..........  5% 1.27M 7s\n",
      "   950K .......... .......... .......... .......... ..........  5% 1.30M 8s\n",
      "  1000K .......... .......... .......... .......... ..........  6% 81.7M 7s\n",
      "  1050K .......... .......... .......... .......... ..........  6%  144M 7s\n",
      "  1100K .......... .......... .......... .......... ..........  6%  126M 7s\n",
      "  1150K .......... .......... .......... .......... ..........  7%  147M 6s\n",
      "  1200K .......... .......... .......... .......... ..........  7%  241M 6s\n",
      "  1250K .......... .......... .......... .......... ..........  7%  243M 6s\n",
      "  1300K .......... .......... .......... .......... ..........  7%  177M 6s\n",
      "  1350K .......... .......... .......... .......... ..........  8%  153M 5s\n",
      "  1400K .......... .......... .......... .......... ..........  8%  232M 5s\n",
      "  1450K .......... .......... .......... .......... ..........  8%  171M 5s\n",
      "  1500K .......... .......... .......... .......... ..........  9%  250M 5s\n",
      "  1550K .......... .......... .......... .......... ..........  9%  260M 5s\n",
      "  1600K .......... .......... .......... .......... ..........  9%  264M 4s\n",
      "  1650K .......... .......... .......... .......... .......... 10%  266M 4s\n",
      "  1700K .......... .......... .......... .......... .......... 10%  200M 4s\n",
      "  1750K .......... .......... .......... .......... .......... 10%  291M 4s\n",
      "  1800K .......... .......... .......... .......... .......... 10%  246M 4s\n",
      "  1850K .......... .......... .......... .......... .......... 11% 1.30M 4s\n",
      "  1900K .......... .......... .......... .......... .......... 11% 1.30M 4s\n",
      "  1950K .......... .......... .......... .......... .......... 11%  183M 4s\n",
      "  2000K .......... .......... .......... .......... .......... 12%  215M 4s\n",
      "  2050K .......... .......... .......... .......... .......... 12%  171M 4s\n",
      "  2100K .......... .......... .......... .......... .......... 12%  236M 4s\n",
      "  2150K .......... .......... .......... .......... .......... 13%  254M 4s\n",
      "  2200K .......... .......... .......... .......... .......... 13%  101M 4s\n",
      "  2250K .......... .......... .......... .......... .......... 13%  201M 4s\n",
      "  2300K .......... .......... .......... .......... .......... 13%  210M 3s\n",
      "  2350K .......... .......... .......... .......... .......... 14%  192M 3s\n",
      "  2400K .......... .......... .......... .......... .......... 14%  202M 3s\n",
      "  2450K .......... .......... .......... .......... .......... 14%  295M 3s\n",
      "  2500K .......... .......... .......... .......... .......... 15%  233M 3s\n",
      "  2550K .......... .......... .......... .......... .......... 15%  232M 3s\n",
      "  2600K .......... .......... .......... .......... .......... 15%  151M 3s\n",
      "  2650K .......... .......... .......... .......... .......... 15%  310M 3s\n",
      "  2700K .......... .......... .......... .......... .......... 16%  281M 3s\n",
      "  2750K .......... .......... .......... .......... .......... 16%  234M 3s\n",
      "  2800K .......... .......... .......... .......... .......... 16%  332M 3s\n",
      "  2850K .......... .......... .......... .......... .......... 17%  324M 3s\n",
      "  2900K .......... .......... .......... .......... .......... 17%  286M 3s\n",
      "  2950K .......... .......... .......... .......... .......... 17%  275M 3s\n",
      "  3000K .......... .......... .......... .......... .......... 18%  294M 3s\n",
      "  3050K .......... .......... .......... .......... .......... 18%  294M 3s\n",
      "  3100K .......... .......... .......... .......... .......... 18%  355M 2s\n",
      "  3150K .......... .......... .......... .......... .......... 18%  245M 2s\n",
      "  3200K .......... .......... .......... .......... .......... 19%  286M 2s\n",
      "  3250K .......... .......... .......... .......... .......... 19%  297M 2s\n",
      "  3300K .......... .......... .......... .......... .......... 19%  299M 2s\n",
      "  3350K .......... .......... .......... .......... .......... 20%  280M 2s\n",
      "  3400K .......... .......... .......... .......... .......... 20%  682K 2s\n",
      "  3450K .......... .......... .......... .......... .......... 20%  176M 2s\n",
      "  3500K .......... .......... .......... .......... .......... 20%  131M 2s\n",
      "  3550K .......... .......... .......... .......... .......... 21%  166M 2s\n",
      "  3600K .......... .......... .......... .......... .......... 21%  168M 2s\n",
      "  3650K .......... .......... .......... .......... .......... 21%  145M 2s\n",
      "  3700K .......... .......... .......... .......... .......... 22%  250M 2s\n",
      "  3750K .......... .......... .......... .......... .......... 22% 78.2M 2s\n",
      "  3800K .......... .......... .......... .......... .......... 22%  194M 2s\n",
      "  3850K .......... .......... .......... .......... .......... 23%  203M 2s\n",
      "  3900K .......... .......... .......... .......... .......... 23%  232M 2s\n",
      "  3950K .......... .......... .......... .......... .......... 23%  162M 2s\n",
      "  4000K .......... .......... .......... .......... .......... 23%  185M 2s\n",
      "  4050K .......... .......... .......... .......... .......... 24%  239M 2s\n",
      "  4100K .......... .......... .......... .......... .......... 24%  160M 2s\n",
      "  4150K .......... .......... .......... .......... .......... 24%  149M 2s\n",
      "  4200K .......... .......... .......... .......... .......... 25%  171M 2s\n",
      "  4250K .......... .......... .......... .......... .......... 25%  204M 2s\n",
      "  4300K .......... .......... .......... .......... .......... 25%  193M 2s\n",
      "  4350K .......... .......... .......... .......... .......... 26%  160M 2s\n",
      "  4400K .......... .......... .......... .......... .......... 26%  198M 2s\n",
      "  4450K .......... .......... .......... .......... .......... 26%  170M 2s\n",
      "  4500K .......... .......... .......... .......... .......... 26%  232M 2s\n",
      "  4550K .......... .......... .......... .......... .......... 27%  172M 2s\n",
      "  4600K .......... .......... .......... .......... .......... 27%  229M 2s\n",
      "  4650K .......... .......... .......... .......... .......... 27%  160M 2s\n",
      "  4700K .......... .......... .......... .......... .......... 28%  328M 2s\n",
      "  4750K .......... .......... .......... .......... .......... 28%  285M 2s\n",
      "  4800K .......... .......... .......... .......... .......... 28% 99.7M 2s\n",
      "  4850K .......... .......... .......... .......... .......... 28%  165M 2s\n",
      "  4900K .......... .......... .......... .......... .......... 29%  244M 2s\n",
      "  4950K .......... .......... .......... .......... .......... 29%  703K 2s\n",
      "  5000K .......... .......... .......... .......... .......... 29%  151M 2s\n",
      "  5050K .......... .......... .......... .......... .......... 30%  211M 2s\n",
      "  5100K .......... .......... .......... .......... .......... 30% 93.2M 2s\n",
      "  5150K .......... .......... .......... .......... .......... 30%  131M 2s\n",
      "  5200K .......... .......... .......... .......... .......... 31%  163M 2s\n",
      "  5250K .......... .......... .......... .......... .......... 31% 92.6M 2s\n",
      "  5300K .......... .......... .......... .......... .......... 31%  167M 2s\n",
      "  5350K .......... .......... .......... .......... .......... 31%  143M 2s\n",
      "  5400K .......... .......... .......... .......... .......... 32%  350M 2s\n",
      "  5450K .......... .......... .......... .......... .......... 32% 49.0M 1s\n",
      "  5500K .......... .......... .......... .......... .......... 32%  179M 1s\n",
      "  5550K .......... .......... .......... .......... .......... 33%  145M 1s\n",
      "  5600K .......... .......... .......... .......... .......... 33%  157M 1s\n",
      "  5650K .......... .......... .......... .......... .......... 33%  145M 1s\n",
      "  5700K .......... .......... .......... .......... .......... 33%  183M 1s\n",
      "  5750K .......... .......... .......... .......... .......... 34%  220M 1s\n",
      "  5800K .......... .......... .......... .......... .......... 34%  190M 1s\n",
      "  5850K .......... .......... .......... .......... .......... 34%  170M 1s\n",
      "  5900K .......... .......... .......... .......... .......... 35%  197M 1s\n",
      "  5950K .......... .......... .......... .......... .......... 35%  192M 1s\n",
      "  6000K .......... .......... .......... .......... .......... 35%  207M 1s\n",
      "  6050K .......... .......... .......... .......... .......... 36%  249M 1s\n",
      "  6100K .......... .......... .......... .......... .......... 36%  349M 1s\n",
      "  6150K .......... .......... .......... .......... .......... 36%  310M 1s\n",
      "  6200K .......... .......... .......... .......... .......... 36%  351M 1s\n",
      "  6250K .......... .......... .......... .......... .......... 37%  321M 1s\n",
      "  6300K .......... .......... .......... .......... .......... 37%  162M 1s\n",
      "  6350K .......... .......... .......... .......... .......... 37%  152M 1s\n",
      "  6400K .......... .......... .......... .......... .......... 38%  336M 1s\n",
      "  6450K .......... .......... .......... .......... .......... 38% 1.44M 1s\n",
      "  6500K .......... .......... .......... .......... .......... 38% 1.31M 1s\n",
      "  6550K .......... .......... .......... .......... .......... 39%  130M 1s\n",
      "  6600K .......... .......... .......... .......... .......... 39% 94.3M 1s\n",
      "  6650K .......... .......... .......... .......... .......... 39%  131M 1s\n",
      "  6700K .......... .......... .......... .......... .......... 39%  151M 1s\n",
      "  6750K .......... .......... .......... .......... .......... 40%  205M 1s\n",
      "  6800K .......... .......... .......... .......... .......... 40%  127M 1s\n",
      "  6850K .......... .......... .......... .......... .......... 40%  152M 1s\n",
      "  6900K .......... .......... .......... .......... .......... 41%  158M 1s\n",
      "  6950K .......... .......... .......... .......... .......... 41% 56.4M 1s\n",
      "  7000K .......... .......... .......... .......... .......... 41%  155M 1s\n",
      "  7050K .......... .......... .......... .......... .......... 41% 58.5M 1s\n",
      "  7100K .......... .......... .......... .......... .......... 42%  198M 1s\n",
      "  7150K .......... .......... .......... .......... .......... 42%  113M 1s\n",
      "  7200K .......... .......... .......... .......... .......... 42%  154M 1s\n",
      "  7250K .......... .......... .......... .......... .......... 43%  151M 1s\n",
      "  7300K .......... .......... .......... .......... .......... 43%  188M 1s\n",
      "  7350K .......... .......... .......... .......... .......... 43%  157M 1s\n",
      "  7400K .......... .......... .......... .......... .......... 44%  192M 1s\n",
      "  7450K .......... .......... .......... .......... .......... 44%  259M 1s\n",
      "  7500K .......... .......... .......... .......... .......... 44%  215M 1s\n",
      "  7550K .......... .......... .......... .......... .......... 44% 60.0M 1s\n",
      "  7600K .......... .......... .......... .......... .......... 45%  136M 1s\n",
      "  7650K .......... .......... .......... .......... .......... 45%  112M 1s\n",
      "  7700K .......... .......... .......... .......... .......... 45%  190M 1s\n",
      "  7750K .......... .......... .......... .......... .......... 46%  141M 1s\n",
      "  7800K .......... .......... .......... .......... .......... 46%  157M 1s\n",
      "  7850K .......... .......... .......... .......... .......... 46%  176M 1s\n",
      "  7900K .......... .......... .......... .......... .......... 47%  198M 1s\n",
      "  7950K .......... .......... .......... .......... .......... 47%  196M 1s\n",
      "  8000K .......... .......... .......... .......... .......... 47%  729K 1s\n",
      "  8050K .......... .......... .......... .......... .......... 47%  138M 1s\n",
      "  8100K .......... .......... .......... .......... .......... 48%  138M 1s\n",
      "  8150K .......... .......... .......... .......... .......... 48% 99.1M 1s\n",
      "  8200K .......... .......... .......... .......... .......... 48%  108M 1s\n",
      "  8250K .......... .......... .......... .......... .......... 49%  194M 1s\n",
      "  8300K .......... .......... .......... .......... .......... 49%  207M 1s\n",
      "  8350K .......... .......... .......... .......... .......... 49%  117M 1s\n",
      "  8400K .......... .......... .......... .......... .......... 49%  157M 1s\n",
      "  8450K .......... .......... .......... .......... .......... 50%  122M 1s\n",
      "  8500K .......... .......... .......... .......... .......... 50% 58.0M 1s\n",
      "  8550K .......... .......... .......... .......... .......... 50%  193M 1s\n",
      "  8600K .......... .......... .......... .......... .......... 51% 57.2M 1s\n",
      "  8650K .......... .......... .......... .......... .......... 51%  254M 1s\n",
      "  8700K .......... .......... .......... .......... .......... 51%  131M 1s\n",
      "  8750K .......... .......... .......... .......... .......... 52%  117M 1s\n",
      "  8800K .......... .......... .......... .......... .......... 52% 56.6M 1s\n",
      "  8850K .......... .......... .......... .......... .......... 52%  187M 1s\n",
      "  8900K .......... .......... .......... .......... .......... 52%  194M 1s\n",
      "  8950K .......... .......... .......... .......... .......... 53%  167M 1s\n",
      "  9000K .......... .......... .......... .......... .......... 53%  173M 1s\n",
      "  9050K .......... .......... .......... .......... .......... 53%  330M 1s\n",
      "  9100K .......... .......... .......... .......... .......... 54%  197M 1s\n",
      "  9150K .......... .......... .......... .......... .......... 54%  137M 1s\n",
      "  9200K .......... .......... .......... .......... .......... 54% 99.6M 1s\n",
      "  9250K .......... .......... .......... .......... .......... 54%  158M 1s\n",
      "  9300K .......... .......... .......... .......... .......... 55%  193M 1s\n",
      "  9350K .......... .......... .......... .......... .......... 55%  153M 1s\n",
      "  9400K .......... .......... .......... .......... .......... 55% 61.9M 1s\n",
      "  9450K .......... .......... .......... .......... .......... 56%  174M 1s\n",
      "  9500K .......... .......... .......... .......... .......... 56%  258M 1s\n",
      "  9550K .......... .......... .......... .......... .......... 56%  732K 1s\n",
      "  9600K .......... .......... .......... .......... .......... 57%  204M 1s\n",
      "  9650K .......... .......... .......... .......... .......... 57%  224M 1s\n",
      "  9700K .......... .......... .......... .......... .......... 57%  111M 1s\n",
      "  9750K .......... .......... .......... .......... .......... 57%  101M 1s\n",
      "  9800K .......... .......... .......... .......... .......... 58%  176M 1s\n",
      "  9850K .......... .......... .......... .......... .......... 58%  195M 1s\n",
      "  9900K .......... .......... .......... .......... .......... 58%  136M 1s\n",
      "  9950K .......... .......... .......... .......... .......... 59% 49.8M 1s\n",
      " 10000K .......... .......... .......... .......... .......... 59%  141M 1s\n",
      " 10050K .......... .......... .......... .......... .......... 59%  139M 1s\n",
      " 10100K .......... .......... .......... .......... .......... 60% 71.2M 1s\n",
      " 10150K .......... .......... .......... .......... .......... 60%  125M 1s\n",
      " 10200K .......... .......... .......... .......... .......... 60%  179M 1s\n",
      " 10250K .......... .......... .......... .......... .......... 60%  181M 1s\n",
      " 10300K .......... .......... .......... .......... .......... 61%  156M 1s\n",
      " 10350K .......... .......... .......... .......... .......... 61% 41.0M 1s\n",
      " 10400K .......... .......... .......... .......... .......... 61%  205M 1s\n",
      " 10450K .......... .......... .......... .......... .......... 62%  189M 1s\n",
      " 10500K .......... .......... .......... .......... .......... 62%  218M 1s\n",
      " 10550K .......... .......... .......... .......... .......... 62%  241M 1s\n",
      " 10600K .......... .......... .......... .......... .......... 62%  179M 1s\n",
      " 10650K .......... .......... .......... .......... .......... 63%  185M 1s\n",
      " 10700K .......... .......... .......... .......... .......... 63%  155M 1s\n",
      " 10750K .......... .......... .......... .......... .......... 63%  109M 1s\n",
      " 10800K .......... .......... .......... .......... .......... 64%  125M 1s\n",
      " 10850K .......... .......... .......... .......... .......... 64% 73.8M 1s\n",
      " 10900K .......... .......... .......... .......... .......... 64%  219M 1s\n",
      " 10950K .......... .......... .......... .......... .......... 65% 70.5M 1s\n",
      " 11000K .......... .......... .......... .......... .......... 65%  199M 1s\n",
      " 11050K .......... .......... .......... .......... .......... 65% 1.56M 1s\n",
      " 11100K .......... .......... .......... .......... .......... 65% 1.33M 1s\n",
      " 11150K .......... .......... .......... .......... .......... 66%  175M 1s\n",
      " 11200K .......... .......... .......... .......... .......... 66% 32.7M 1s\n",
      " 11250K .......... .......... .......... .......... .......... 66%  154M 1s\n",
      " 11300K .......... .......... .......... .......... .......... 67%  179M 1s\n",
      " 11350K .......... .......... .......... .......... .......... 67%  157M 1s\n",
      " 11400K .......... .......... .......... .......... .......... 67%  157M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 67%  112M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 68%  130M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 68% 99.0M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 68%  149M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 69%  225M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 69%  190M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 69%  142M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 70%  213M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 70%  165M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 70% 44.2M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 70%  147M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 71%  244M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 71%  176M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 71%  204M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 72%  217M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 72%  152M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 72%  136M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 73% 77.5M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 73%  162M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 73%  116M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 73% 74.7M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 74%  152M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 74%  197M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 74%  735K 0s\n",
      " 12650K .......... .......... .......... .......... .......... 75%  156M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 75%  294M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 75% 36.8M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 75%  160M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 76%  161M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 76%  170M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 76%  100M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 77%  182M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 77%  152M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 77% 95.6M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 78%  131M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 78%  103M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 78%  147M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 78%  169M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 79%  175M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 79% 34.4M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 79%  192M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 80%  170M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 80%  133M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 80%  201M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 80%  190M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 81%  239M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 81%  306M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 81%  163M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 82% 95.1M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 82%  311M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 82%  255M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 83% 41.7M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 83%  266M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 83%  270M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 83%  738K 0s\n",
      " 14200K .......... .......... .......... .......... .......... 84%  159M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 84%  109M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 84% 54.4M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 85%  127M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 85%  117M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 85%  194M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 86% 57.4M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 86%  156M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 86%  274M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 86%  176M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 87% 71.2M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 87%  124M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 87%  222M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 88%  227M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 88%  144M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 88% 38.8M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 88%  143M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 89%  140M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 89%  144M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 89%  120M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 90%  178M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 90%  350M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 90%  340M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 91%  141M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 91%  148M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 91%  201M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 91%  281M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 92% 36.6M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 92%  171M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 92%  744K 0s\n",
      " 15700K .......... .......... .......... .......... .......... 93%  159M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 93%  159M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 93%  104M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 94% 59.7M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 94%  125M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 94%  109M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 94% 38.7M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 95%  187M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 95%  175M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 95% 81.8M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 96% 83.9M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 96%  184M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 96% 83.9M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 96%  190M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 97%  185M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 97%  127M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 97% 67.1M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 98%  187M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 98%  190M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 98%  286M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 99%  233M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 99% 62.4M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 99%  135M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 99%  360M 0s\n",
      " 16900K .......... ...                                        100%  314M=1.3s\n",
      "\n",
      "2019-04-30 23:54:18 (12.9 MB/s) - ‘mleap_spark_assembly.jar.3’ saved [17319576/17319576]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Download Raw data and Dependencies\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\n",
    "wget https://s3-us-west-2.amazonaws.com/sparkml-mleap/0.9.6/python/python.zip\n",
    "wget https://s3-us-west-2.amazonaws.com/sparkml-mleap/0.9.6/jar/mleap_spark_assembly.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-glue-process-277454758150-us-east-1/data/car.data\n",
      "s3://sagemaker-glue-process-277454758150-us-east-1/scripts/preprocessor.py\n",
      "s3://sagemaker-glue-process-277454758150-us-east-1/scripts/python.zip\n",
      "s3://sagemaker-glue-process-277454758150-us-east-1/scripts/mleap_spark_assembly.jar\n"
     ]
    }
   ],
   "source": [
    "# Uploading the training data to S3\n",
    "result = sess.upload_data(path='car.data', bucket=bucket_name, key_prefix='data')\n",
    "print(result)\n",
    "result = sess.upload_data(path='preprocessor.py', bucket=bucket_name, key_prefix='scripts')\n",
    "print(result)\n",
    "result = sess.upload_data(path='python.zip', bucket=bucket_name, key_prefix='scripts')\n",
    "print(result)\n",
    "result = sess.upload_data(path='mleap_spark_assembly.jar', bucket=bucket_name, key_prefix='scripts')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your S3 bucket is now setup for our pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4  ACCESS the instructions in the github to prepare and execute the glue job \n",
    "\n",
    "Preprocessing using Apache Spark in AWS Glue\n",
    "\n",
    "If you take a look at the data we downloaded, you’ll notice all of the fields are categorical data in string format, which XGBoost cannot natively handle. In order to utilize SageMaker’s XGBoost, we need to preprocess our data into a series of one hot encoded columns. Apache Spark provides preprocessing pipeline capabilities that we will utilize. \n",
    "\n",
    "You’ll notice we unzip this archive and re-archive it into a tar.gz file that SageMaker recognizes.\n",
    "To run our Spark pipelines within SageMaker, we are going to utilize our notebook instance.  \n",
    "\n",
    "\n",
    "## 1.5 Create and run AWS Glue Preprocessing Job (###SKIP THIS IF MANUAL JOB HAS RUN SUCCESSFULLY)\n",
    "\n",
    "Next we'll be creating Glue client via Boto so that we can invoke the `create_job` API of Glue. `create_job` API will create a job definition which can be used to execute your jobs in Glue. The job definition created here is mutable. While creating the job, we are also passing the code location as well as the dependencies location to Glue.\n",
    "\n",
    "The  job will be executed by calling `start_job_run` API. This API creates an immutable run/execution corresponding to the job definition created above. We will require the `job_run_id` for the particular job execution to check for status. We'll pass the data and model locations as part of the job execution parameters.\n",
    "\n",
    "Finally we will check for the job status to see if it has `succeeded`, `failed` or `stopped`. Once the job is succeeded, we have the transformed data into S3 in CSV format which we can use with XGBoost for training. If the job fails, you can go to [AWS Glue console](https://us-west-2.console.aws.amazon.com/glue/home), click on **Jobs** tab on the left, and from the page, click on this particular job and you will be able to find the CloudWatch logs (the link under **Logs**) link for these jobs which can help you to see what exactly went wrong in the job execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and run AWS Glue Preprocessing Job\n",
    "###SKIP THIS IF MANUAL JOB HAS RUN SUCCESSFULLY\n",
    "# Define the Job in AWS Glue\n",
    "glue = boto3.client('glue')\n",
    "\n",
    "try:\n",
    "    glue.get_job(JobName='preprocessing-cars')\n",
    "    print(\"Job already exists, continuing...\")\n",
    "except glue.exceptions.EntityNotFoundException:\n",
    "    response = glue.create_job(\n",
    "        Name='preprocessing-cars',\n",
    "        Role=role,\n",
    "        Command={\n",
    "            'Name': 'glueetl',\n",
    "            'ScriptLocation': 's3://{}/scripts/preprocessor.py'.format(bucket_name)\n",
    "        },\n",
    "        DefaultArguments={\n",
    "            '--s3_input_data_location': 's3://{}/data/car.data'.format(bucket_name),\n",
    "            '--s3_model_bucket_prefix': 'model',\n",
    "            '--s3_model_bucket': bucket_name,\n",
    "            '--s3_output_bucket': bucket_name,\n",
    "            '--s3_output_bucket_prefix': 'output',\n",
    "            '--extra-py-files': 's3://{}/scripts/python.zip'.format(bucket_name),\n",
    "            '--extra-jars': 's3://{}/scripts/mleap_spark_assembly.jar'.format(bucket_name)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print('{}\\n'.format(response))\n",
    "\n",
    "# Run the job in AWS Glue\n",
    "try:\n",
    "    job_name='preprocessing-cars'\n",
    "    response = glue.start_job_run(JobName=job_name)\n",
    "    job_run_id = response['JobRunId']\n",
    "    print('{}\\n'.format(response))\n",
    "except glue.exceptions.ConcurrentRunsExceededException:\n",
    "    print(\"Job run already in progress, continuing...\")\n",
    "\n",
    "    \n",
    "# Check on the job status\n",
    "import time\n",
    "\n",
    "job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "while job_run_status not in ('FAILED', 'SUCCEEDED', 'STOPPED'):\n",
    "    job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "    print (job_run_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we have now preprocessed our data into a training and validation set, with one-hot encoding for all of the string values. We have also serialized a preprocessor and post-processor into the MLeap format, so that we can reuse these pipelines in our endpoint later. The next step is to train a Machine Learning model. We will be using Amazon SageMaker’s built-in XGBoost for this.\n",
    "\n",
    "\n",
    "#  Lab 2 -Machine Learning Process\n",
    "\n",
    "\n",
    "\n",
    "## Training an Amazon SageMaker XGBoost Model\n",
    "\n",
    "Now that we have our data preprocessed in a format that XGBoost recognizes, we can run a simple training job to train a classifier model on our data. We can run this entire process in our Jupyter notebook. Run the following cell, labeled Run Amazon SageMaker XGBoost Training Job. This will run our XGBoost training job in Amazon SageMaker, and monitor the progress of the job. Once the job is ‘Completed’, you can move on to the next cell.\n",
    " \n",
    "This will train the model on the preprocessed data we created earlier. After a few minutes, usually less than 5, the job should complete successfully, and output our model artifacts to the S3 location we specified. Once this is done, we can deploy an inference pipeline that consists of pre-processing, inference and post-processing steps.\n",
    "\n",
    "## 2.1 Run Amazon SageMaker XGBoost Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Amazon SageMaker XGBoost Training Job\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Get XGBoost container image for current region\n",
    "training_image = get_image_uri(region, 'xgboost', repo_version=\"latest\")\n",
    "\n",
    "# Create a unique training job name\n",
    "training_job_name = 'xgboost-cars-'+''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(8))\n",
    "\n",
    "# Create the training job in Amazon SageMaker\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "response = sagemaker.create_training_job(\n",
    "    TrainingJobName=training_job_name,\n",
    "    HyperParameters={\n",
    "        'early_stopping_rounds ': '5',\n",
    "        'num_round': '10',\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '4',\n",
    "        'eval_metric': 'mlogloss'\n",
    "\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'TrainingImage': training_image,\n",
    "        'TrainingInputMode': 'File',\n",
    "    },\n",
    "    RoleArn=role,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'train',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': 's3://{}/output/train'.format(bucket_name),\n",
    "                    'S3DataDistributionType': 'FullyReplicated'\n",
    "                }\n",
    "            },\n",
    "            'ContentType': 'text/csv',\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'None',\n",
    "            'InputMode': 'File'\n",
    "        },\n",
    "        {\n",
    "            'ChannelName': 'validation',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': 's3://{}/output/validation'.format(bucket_name),\n",
    "                    'S3DataDistributionType': 'FullyReplicated'\n",
    "                }\n",
    "            },\n",
    "            'ContentType': 'text/csv',\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'None',\n",
    "            'InputMode': 'File'\n",
    "        },\n",
    "    ],\n",
    "    OutputDataConfig={\n",
    "        'S3OutputPath': 's3://{}/xgb'.format(bucket_name)\n",
    "    },\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.m4.xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 1\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 3600\n",
    "    },)\n",
    "\n",
    "print('{}\\n'.format(response))\n",
    "\n",
    "# Monitor the status until completed\n",
    "job_run_status = sagemaker.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    job_run_status = sagemaker.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "    print (job_run_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Deploying an Amazon SageMaker Endpoint utilizing your data processing artifacts\n",
    "\n",
    "Now that we have a set of model artifacts, we can set up an inference pipeline that executes sequentially in Amazon SageMaker. We start by setting up a Model, which will point to all of our model artifacts, then we setup an Endpoint configuration to specify our hardware, and finally we can stand up an Endpoint. With this endpoint, we will pass the raw data and no longer need to write pre-processing logic in our application code. The same pre-processing steps that ran for training can be applied to inference input data for better consistency and ease of management.\n",
    "\n",
    "Deploying a model in SageMaker requires two components:\n",
    "\n",
    "* Docker image residing in ECR.\n",
    "* Model artifacts residing in S3.\n",
    "\n",
    "**SparkML**\n",
    "\n",
    "For SparkML, Docker image for MLeap based SparkML serving is provided by SageMaker team. For more information on this, please see [SageMaker SparkML Serving](https://github.com/aws/sagemaker-sparkml-serving-container). MLeap serialized SparkML model was uploaded to S3 as part of the SparkML job we executed in AWS Glue.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "For XGBoost, we will use the same Docker image we used for training. The model artifacts for XGBoost was uploaded as part of the training job we just ran.\n",
    "\n",
    "\n",
    "## Create SageMaker Endpoint with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create SageMaker endpoint with pipeline\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Image locations are published at: https://github.com/aws/sagemaker-sparkml-serving-container\n",
    "sparkml_images = {\n",
    "    'us-west-1': '746614075791.dkr.ecr.us-west-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'us-west-2': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'us-east-1': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'us-east-2': '257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ap-northeast-1': '354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ap-northeast-2': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ap-southeast-1': '121021644041.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ap-southeast-2': '783357654285.dkr.ecr.ap-southeast-2.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ap-south-1': '720646828776.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'eu-west-1': '141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'eu-west-2': '764974769150.dkr.ecr.eu-west-2.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'eu-central-1': '492215442770.dkr.ecr.eu-central-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'ca-central-1': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-sparkml-serving:2.2',\n",
    "    'us-gov-west-1': '414596584902.dkr.ecr.us-gov-west-1.amazonaws.com/sagemaker-sparkml-serving:2.2'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    sparkml_image = sparkml_images[region]\n",
    "\n",
    "    response = sagemaker.create_model(\n",
    "        ModelName='pipeline-car-evaluation',\n",
    "        Containers=[\n",
    "            {\n",
    "                'Image': sparkml_image,\n",
    "                'ModelDataUrl': 's3://{}/model/model.tar.gz'.format(bucket_name),\n",
    "                'Environment': {\n",
    "                    'SAGEMAKER_SPARKML_SCHEMA': '{\"input\":[{\"type\":\"string\",\"name\":\"buying\"},{\"type\":\"string\",\"name\":\"maint\"},{\"type\":\"string\",\"name\":\"doors\"},{\"type\":\"string\",\"name\":\"persons\"},{\"type\":\"string\",\"name\":\"lug_boot\"},{\"type\":\"string\",\"name\":\"safety\"}],\"output\":{\"type\":\"double\",\"name\":\"features\",\"struct\":\"vector\"}}'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'Image': training_image,\n",
    "                'ModelDataUrl': 's3://{}/xgb/{}/output/model.tar.gz'.format(bucket_name, training_job_name)\n",
    "            },\n",
    "            {\n",
    "                'Image': sparkml_image,\n",
    "                'ModelDataUrl': 's3://{}/model/postprocess.tar.gz'.format(bucket_name),\n",
    "                'Environment': {\n",
    "                    'SAGEMAKER_SPARKML_SCHEMA': '{\"input\": [{\"type\": \"double\", \"name\": \"label\"}], \"output\": {\"type\": \"string\", \"name\": \"cat\"}}'\n",
    "                }\n",
    "\n",
    "            },\n",
    "        ],\n",
    "        ExecutionRoleArn=role\n",
    "    )\n",
    "\n",
    "    print('{}\\n'.format(response))\n",
    "    \n",
    "except ClientError:\n",
    "    print('Model already exists, continuing...')\n",
    "\n",
    "\n",
    "try:\n",
    "    response = sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName='pipeline-car-evaluation',\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'DefaultVariant',\n",
    "                'ModelName': 'pipeline-car-evaluation',\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InstanceType': 'ml.m4.xlarge',\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    print('{}\\n'.format(response))\n",
    "\n",
    "except ClientError:\n",
    "    print('Endpoint config already exists, continuing...')\n",
    "\n",
    "\n",
    "try:\n",
    "    response = sagemaker.create_endpoint(\n",
    "        EndpointName='pipeline-car-evaluation',\n",
    "        EndpointConfigName='pipeline-car-evaluation',\n",
    "    )\n",
    "    print('{}\\n'.format(response))\n",
    "\n",
    "except ClientError:\n",
    "    print(\"Endpoint already exists, continuing...\")\n",
    "\n",
    "\n",
    "# Monitor the status until completed\n",
    "endpoint_status = sagemaker.describe_endpoint(EndpointName='pipeline-car-evaluation')['EndpointStatus']\n",
    "while endpoint_status not in ('OutOfService','InService','Failed'):\n",
    "    endpoint_status = sagemaker.describe_endpoint(EndpointName='pipeline-car-evaluation')['EndpointStatus']\n",
    "    print(endpoint_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few minutes, Amazon SageMaker will have created an endpoint utilizing all three of the provided containers on a single instance. When the endpoint is invoked with a payload, the output of the earlier containers is passed as the input to the later containers, until the payload reaches its final output.\n",
    "\n",
    "In this scenario, the raw, string categories are sent to our preprocessing SparkML serving container and run through a Spark pipeline to one hot encode the features. Then the one hot encoded data is sent to our XGBoost container, where our model makes a prediction to an index. The index is then fed to our post-processing MLeap container, with a Spark model artifact, which converts the index back to its original label string, which is returned to the client. These are the exact same steps you used for pre-processing training data and it was only necessary to write the code once.\n",
    "\n",
    "## 2.3 Testing the Endpoint\n",
    "\n",
    "Once the Amazon SageMaker endpoint is InService, we can test it with the code cell labeled Invoke the Endpoint. If successful, this should return one of the following values: `unacc`, `acc`, `good`, `vgood`.\n",
    "\n",
    "## 2.4 Invoke the Endpoint\n",
    "\n",
    "### Invoking the newly created inference endpoint with a payload to transform the data\n",
    "Now we will invoke the endpoint with a valid payload that SageMaker SparkML Serving can recognize. There are three ways in which input payload can be passed to the request:\n",
    "\n",
    "* Pass it as a valid CSV string. In this case, the schema passed via the environment variable will be used to determine the schema. For CSV format, every column in the input has to be a basic datatype (e.g. int, double, string) and it can not be a Spark `Array` or `Vector`.\n",
    "\n",
    "* Pass it as a valid JSON string. In this case as well, the schema passed via the environment variable will be used to infer the schema. With JSON format, every column in the input can be a basic datatype or a Spark `Vector` or `Array` provided that the corresponding entry in the schema mentions the correct value.\n",
    "\n",
    "* Pass the request in JSON format along with the schema and the data. In this case, the schema passed in the payload will take precedence over the one passed via the environment variable (if any).\n",
    "\n",
    "In this case, we will pass it as a valid CSV string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Invoke the Endpoint\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "sample_payload=b'low,low,5more,more,big,high'\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='pipeline-car-evaluation',\n",
    "    Body=sample_payload,\n",
    "    ContentType='text/csv'\n",
    ")\n",
    "\n",
    "print('Our result for this payload is: {}'.format(response['Body'].read().decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Clean up your AWS environment\n",
    "When you are done with this experiment, make sure to delete your SageMaker endpoint to avoid incurring unexpected costs. You can do this from the AWS Console by going to Services, Amazon SageMaker, Inference, and Endpoints. Select pipeline-xgboost under Endpoints. In the upper-right, select Delete. This will remove the endpoint from your AWS account. You will also want to make sure to stop your Notebook instance.\n",
    "\n",
    "A more extensive cleanup can be done from your Notebook instance by running the code cell labeled Environment cleanup, seen below.\n",
    "\n",
    "## Environment cleanup -POST INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment cleanup\n",
    "\n",
    "print('Deleting SageMaker endpoint...')\n",
    "result = sagemaker.delete_endpoint(\n",
    "    EndpointName='pipeline-car-evaluation'\n",
    ")\n",
    "print(result)\n",
    "\n",
    "print('Deleting SageMaker endpoint config...')\n",
    "result = sagemaker.delete_endpoint_config(\n",
    "    EndpointConfigName='pipeline-car-evaluation'\n",
    ")\n",
    "print(result)\n",
    "\n",
    "print('Deleting SageMaker model...')\n",
    "result = sagemaker.delete_model(\n",
    "    ModelName='pipeline-car-evaluation'\n",
    ")\n",
    "print(result)\n",
    "\n",
    "print('Deleting Glue job...')\n",
    "result = glue.delete_job(\n",
    "    JobName='preprocessing-cars'\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
